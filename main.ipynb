{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.activations import relu,linear\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import logging\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal MNIST Images: 300 training, 600 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(10000,)\n",
      "Training images shape: (300, 28, 28)\n",
      "Training labels shape: (300,)\n",
      "Testing images shape: (600, 28, 28)\n",
      "Testing labels shape: (600,)\n"
     ]
    }
   ],
   "source": [
    "#Now let's import non-distilled images from the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)\n",
    "\n",
    "\n",
    "train_count = 300\n",
    "test_count = 600\n",
    "train_images = train_images[:train_count]\n",
    "train_labels = train_labels[:train_count]\n",
    "test_images = test_images[:test_count]\n",
    "test_labels = test_labels[:test_count]\n",
    "\n",
    "\n",
    "print(\"Training images shape:\", train_images.shape)\n",
    "print(\"Training labels shape:\", train_labels.shape)\n",
    "print(\"Testing images shape:\", test_images.shape)\n",
    "print(\"Testing labels shape:\", test_labels.shape)\n",
    "\n",
    "height, width = 28, 28\n",
    "channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set global seed so that results don't vary across runs\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "#model trained on non-distilled MNIST images\n",
    "model_normal = Sequential(\n",
    "    [\n",
    "    #conv layer 1 (relu)\n",
    "    Conv2D(input_shape = (height, width, channels), filters=6, kernel_size=5, strides=1, padding='same', activation='relu', name='conv1'),\n",
    "    #avg pooling\n",
    "    AveragePooling2D(pool_size=2, strides=2, name='pooling1'),\n",
    "    #conv layer 2 (relu)\n",
    "    Conv2D(filters=16, kernel_size=5, strides=1, padding='valid', activation='relu', name='conv2'),\n",
    "    #avg pooling\n",
    "    AveragePooling2D(pool_size=2, strides=2, name='pooling2'),\n",
    "    #conv layer 3 (relu)\n",
    "    Conv2D(filters=120, kernel_size=5, strides=1, padding='valid', activation='relu', name='conv3'),\n",
    "    #flatten\n",
    "    Flatten(),\n",
    "    #fully connected layer 1 (relu)\n",
    "    Dense(84, activation='relu', name='dense1', kernel_regularizer=tf.keras.regularizers.l2(0.1)),\n",
    "    #fully connected layer 2 (linear)\n",
    "    Dense(10, activation='linear', name='dense2')\n",
    "    ], name='LeNet-5'\n",
    ")\n",
    "# filters are the same as output channel\n",
    "\n",
    "model_normal.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-2),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 16.5017 - accuracy: 0.1300\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 5.9935 - accuracy: 0.1167\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 5.1038 - accuracy: 0.1100\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 4.4677 - accuracy: 0.1500\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 3.8106 - accuracy: 0.2833\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 3.2973 - accuracy: 0.4300\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 2.9308 - accuracy: 0.4567\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 2.2933 - accuracy: 0.6800\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.8406 - accuracy: 0.7667\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.5709 - accuracy: 0.8400\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 1.3475 - accuracy: 0.8900\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0437 - accuracy: 0.9267\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9945 - accuracy: 0.9433\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0057 - accuracy: 0.8900\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9069 - accuracy: 0.9300\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8086 - accuracy: 0.9533\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7752 - accuracy: 0.9300\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7118 - accuracy: 0.9333\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6571 - accuracy: 0.9567\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.6782 - accuracy: 0.9433\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6670 - accuracy: 0.9533\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5970 - accuracy: 0.9533\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6103 - accuracy: 0.9400\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5407 - accuracy: 0.9600\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4052 - accuracy: 0.9800\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3671 - accuracy: 0.9667\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.9833\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.9633\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3930 - accuracy: 0.9800\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.9900\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2340 - accuracy: 0.9967\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2001 - accuracy: 0.9900\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1794 - accuracy: 0.9900\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1423 - accuracy: 0.9933\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1198 - accuracy: 0.9967\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1135 - accuracy: 0.9933\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2260 - accuracy: 0.9700\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7091 - accuracy: 0.9000\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0034 - accuracy: 0.8967\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.1627 - accuracy: 0.9000\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8791 - accuracy: 0.9433\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7065 - accuracy: 0.9700\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.8011 - accuracy: 0.9367\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.9351 - accuracy: 0.9333\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7372 - accuracy: 0.9333\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5753 - accuracy: 0.9667\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.9733\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3532 - accuracy: 0.9733\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3000 - accuracy: 0.9833\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2266 - accuracy: 0.9900\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1636 - accuracy: 0.9967\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1325 - accuracy: 0.9933\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2422 - accuracy: 0.9700\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3024 - accuracy: 0.9667\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3079 - accuracy: 0.9900\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2962 - accuracy: 0.9867\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2625 - accuracy: 0.9833\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1987 - accuracy: 0.9867\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 1.0000\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1141 - accuracy: 1.0000\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1016 - accuracy: 0.9933\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1168 - accuracy: 0.9900\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1232 - accuracy: 0.9933\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1272 - accuracy: 0.9900\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1119 - accuracy: 0.9933\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1840 - accuracy: 0.9900\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9933\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1468 - accuracy: 0.9967\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1389 - accuracy: 0.9933\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0992 - accuracy: 1.0000\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0731 - accuracy: 1.0000\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0520 - accuracy: 1.0000\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0376 - accuracy: 1.0000\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 1.0000\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 1.0000\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 1.0000\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 1.0000\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 1.0000\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 1.0000\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9967\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9900\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.9533\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 1.0298 - accuracy: 0.9233\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 1.0874 - accuracy: 0.9300\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8494 - accuracy: 0.9633\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6025 - accuracy: 0.9867\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3746 - accuracy: 0.9933\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2333 - accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1549 - accuracy: 1.0000\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1107 - accuracy: 1.0000\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0836 - accuracy: 1.0000\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0528 - accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0443 - accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0373 - accuracy: 1.0000\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0318 - accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 1.0000\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 1.0000\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0285 - accuracy: 1.0000\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0268 - accuracy: 0.9967\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0365 - accuracy: 0.9967\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9900\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1329 - accuracy: 0.9933\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.9700\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.5133 - accuracy: 0.9500\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.9533\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.9533\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.9667\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7477 - accuracy: 0.9367\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.9767\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.9900\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6433 - accuracy: 0.9667\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5021 - accuracy: 0.9833\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3571 - accuracy: 0.9833\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2544 - accuracy: 0.9867\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.2207 - accuracy: 0.9833\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1727 - accuracy: 0.9933\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.1437 - accuracy: 0.9933\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1087 - accuracy: 0.9933\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0793 - accuracy: 0.9933\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0619 - accuracy: 0.9933\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0507 - accuracy: 0.9933\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0364 - accuracy: 0.9967\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0331 - accuracy: 0.9967\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0285 - accuracy: 0.9967\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.9967\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.9967\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0216 - accuracy: 0.9967\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0200 - accuracy: 0.9967\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0173 - accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0146 - accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0112 - accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 164/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 165/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 166/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 169/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0123 - accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0242 - accuracy: 0.9933\n",
      "Epoch 173/300\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.1120 - accuracy: 0.9867\n",
      "Epoch 174/300\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4531 - accuracy: 0.9833\n",
      "Epoch 175/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.4602 - accuracy: 0.8500\n",
      "Epoch 176/300\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 2.8869 - accuracy: 0.8433\n",
      "Epoch 177/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3.4216 - accuracy: 0.7767\n",
      "Epoch 178/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 2.8435 - accuracy: 0.8633\n",
      "Epoch 179/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.9483 - accuracy: 0.8700\n",
      "Epoch 180/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 1.3526 - accuracy: 0.9200\n",
      "Epoch 181/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.2446 - accuracy: 0.9167\n",
      "Epoch 182/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9346 - accuracy: 0.9333\n",
      "Epoch 183/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.7760 - accuracy: 0.9533\n",
      "Epoch 184/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6009 - accuracy: 0.9700\n",
      "Epoch 185/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.9833\n",
      "Epoch 186/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3886 - accuracy: 0.9867\n",
      "Epoch 187/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3321 - accuracy: 0.9867\n",
      "Epoch 188/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3292 - accuracy: 0.9800\n",
      "Epoch 189/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3912 - accuracy: 0.9667\n",
      "Epoch 190/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3185 - accuracy: 0.9767\n",
      "Epoch 191/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2763 - accuracy: 0.9833\n",
      "Epoch 192/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.2355 - accuracy: 0.9867\n",
      "Epoch 193/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1967 - accuracy: 0.9867\n",
      "Epoch 194/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1672 - accuracy: 0.9867\n",
      "Epoch 195/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9867\n",
      "Epoch 196/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.9867\n",
      "Epoch 197/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.1187 - accuracy: 0.9867\n",
      "Epoch 198/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1090 - accuracy: 0.9867\n",
      "Epoch 199/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1012 - accuracy: 0.9867\n",
      "Epoch 200/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0940 - accuracy: 0.9867\n",
      "Epoch 201/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.0880 - accuracy: 0.9867\n",
      "Epoch 202/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0825 - accuracy: 0.9900\n",
      "Epoch 203/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0780 - accuracy: 0.9900\n",
      "Epoch 204/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0741 - accuracy: 0.9900\n",
      "Epoch 205/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0700 - accuracy: 0.9900\n",
      "Epoch 206/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.9867\n",
      "Epoch 207/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.9900\n",
      "Epoch 208/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0630 - accuracy: 0.9900\n",
      "Epoch 209/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.9900\n",
      "Epoch 210/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0562 - accuracy: 0.9900\n",
      "Epoch 211/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0529 - accuracy: 0.9933\n",
      "Epoch 212/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0512 - accuracy: 0.9900\n",
      "Epoch 213/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0487 - accuracy: 0.9900\n",
      "Epoch 214/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9933\n",
      "Epoch 215/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0442 - accuracy: 0.9900\n",
      "Epoch 216/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9900\n",
      "Epoch 217/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9900\n",
      "Epoch 218/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9933\n",
      "Epoch 219/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0437 - accuracy: 0.9900\n",
      "Epoch 220/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0392 - accuracy: 0.9933\n",
      "Epoch 221/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9933\n",
      "Epoch 222/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0417 - accuracy: 0.9900\n",
      "Epoch 223/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9933\n",
      "Epoch 224/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 0.9900\n",
      "Epoch 225/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0891 - accuracy: 0.9867\n",
      "Epoch 226/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1030 - accuracy: 0.9867\n",
      "Epoch 227/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1049 - accuracy: 0.9867\n",
      "Epoch 228/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1047 - accuracy: 0.9933\n",
      "Epoch 229/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0912 - accuracy: 0.9933\n",
      "Epoch 230/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0723 - accuracy: 0.9933\n",
      "Epoch 231/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.9900\n",
      "Epoch 232/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0570 - accuracy: 0.9867\n",
      "Epoch 233/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.9833\n",
      "Epoch 234/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0554 - accuracy: 0.9867\n",
      "Epoch 235/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0531 - accuracy: 0.9900\n",
      "Epoch 236/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0480 - accuracy: 0.9900\n",
      "Epoch 237/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0465 - accuracy: 0.9900\n",
      "Epoch 238/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0605 - accuracy: 0.9867\n",
      "Epoch 239/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1632 - accuracy: 0.9600\n",
      "Epoch 240/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2894 - accuracy: 0.9767\n",
      "Epoch 241/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.9767\n",
      "Epoch 242/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7273 - accuracy: 0.9400\n",
      "Epoch 243/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.9730 - accuracy: 0.9367\n",
      "Epoch 244/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.1002 - accuracy: 0.9167\n",
      "Epoch 245/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9149 - accuracy: 0.9567\n",
      "Epoch 246/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0017 - accuracy: 0.9133\n",
      "Epoch 247/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9114 - accuracy: 0.9400\n",
      "Epoch 248/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9407 - accuracy: 0.9300\n",
      "Epoch 249/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6187 - accuracy: 0.9600\n",
      "Epoch 250/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5890 - accuracy: 0.9533\n",
      "Epoch 251/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.9633\n",
      "Epoch 252/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.9733\n",
      "Epoch 253/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3620 - accuracy: 0.9733\n",
      "Epoch 254/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2715 - accuracy: 0.9867\n",
      "Epoch 255/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2335 - accuracy: 0.9833\n",
      "Epoch 256/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2524 - accuracy: 0.9867\n",
      "Epoch 257/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.2530 - accuracy: 0.9867\n",
      "Epoch 258/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1991 - accuracy: 0.9900\n",
      "Epoch 259/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1781 - accuracy: 0.9867\n",
      "Epoch 260/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1467 - accuracy: 0.9900\n",
      "Epoch 261/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.9900\n",
      "Epoch 262/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1126 - accuracy: 0.9900\n",
      "Epoch 263/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1022 - accuracy: 0.9900\n",
      "Epoch 264/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9900\n",
      "Epoch 265/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0876 - accuracy: 0.9933\n",
      "Epoch 266/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0858 - accuracy: 0.9933\n",
      "Epoch 267/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9933\n",
      "Epoch 268/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0716 - accuracy: 0.9933\n",
      "Epoch 269/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.9933\n",
      "Epoch 270/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0644 - accuracy: 0.9933\n",
      "Epoch 271/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.9933\n",
      "Epoch 272/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.9933\n",
      "Epoch 273/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9933\n",
      "Epoch 274/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0553 - accuracy: 0.9933\n",
      "Epoch 275/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0519 - accuracy: 0.9933\n",
      "Epoch 276/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0492 - accuracy: 0.9933\n",
      "Epoch 277/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0474 - accuracy: 0.9933\n",
      "Epoch 278/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0455 - accuracy: 0.9933\n",
      "Epoch 279/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0441 - accuracy: 0.9933\n",
      "Epoch 280/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0427 - accuracy: 0.9933\n",
      "Epoch 281/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9933\n",
      "Epoch 282/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9933\n",
      "Epoch 283/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9933\n",
      "Epoch 284/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9933\n",
      "Epoch 285/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0395 - accuracy: 0.9933\n",
      "Epoch 286/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.0385 - accuracy: 0.9933\n",
      "Epoch 287/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0425 - accuracy: 0.9900\n",
      "Epoch 288/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0483 - accuracy: 0.9933\n",
      "Epoch 289/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0651 - accuracy: 0.9900\n",
      "Epoch 290/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1681 - accuracy: 0.9800\n",
      "Epoch 291/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.1775 - accuracy: 0.9767\n",
      "Epoch 292/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.3273 - accuracy: 0.9800\n",
      "Epoch 293/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.9833\n",
      "Epoch 294/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.9833\n",
      "Epoch 295/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.9700\n",
      "Epoch 296/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.4952 - accuracy: 0.9700\n",
      "Epoch 297/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7172 - accuracy: 0.9467\n",
      "Epoch 298/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.7372 - accuracy: 0.9267\n",
      "Epoch 299/300\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 0.7216 - accuracy: 0.9633\n",
      "Epoch 300/300\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.6898 - accuracy: 0.9733\n",
      "Took 14.38021 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model_normal.fit(train_images, train_labels, epochs=300)\n",
    "\n",
    "#Display duration\n",
    "duration_norm = time() - start\n",
    "print(f'Took {duration_norm:.5f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LeNet-5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (Conv2D)              (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " pooling1 (AveragePooling2D  (None, 14, 14, 6)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " pooling2 (AveragePooling2D  (None, 5, 5, 16)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 1, 1, 120)         48120     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 120)               0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 84)                10164     \n",
      "                                                                 \n",
      " dense2 (Dense)              (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61706 (241.04 KB)\n",
      "Trainable params: 61706 (241.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_normal.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the categorization error\n",
    "#y: target value\n",
    "#yhat: predicted value\n",
    "#cerr: % incorrect\n",
    "\n",
    "def eval_cat_err(y, yhat):\n",
    "    m = len(y)\n",
    "    incorrect = 0\n",
    "    for i in range(m):\n",
    "       if yhat[i] != y[i]:\n",
    "            incorrect+=1\n",
    "    cerr = incorrect / m\n",
    "    \n",
    "    return(cerr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Image per Class (5 samples = 50 images total): 30 training, 10 cv, 10 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_size:  10  Height:  28  Width:  28  Channels:  1\n"
     ]
    }
   ],
   "source": [
    "input = torch.load('<--filepath-->')        #<------Use filepath to the 1ipc .pt file\n",
    "\n",
    "#Check visualization of a single synthetic set without labels\n",
    "# print(input['data'][0][0])\n",
    "\n",
    "#Reshape tensor objects from batch_size, channels, height, width -> batch_size, height, width, channels using torch.permute() and numpy\n",
    "#Create list of tensor objects without labels\n",
    "#Framework conflict: Must convert PyTorch tensors into TensorFlow tensors by converting list into numpy array then converting to TF tensors\n",
    "X=[]\n",
    "for i in range(5):\n",
    "    permuted = input['data'][i][0].permute(0, 2, 3, 1)\n",
    "    numpy_X = permuted.numpy()\n",
    "    tf_X = tf.convert_to_tensor(numpy_X, dtype = tf.float32)\n",
    "    X.append(tf_X)\n",
    "\n",
    "#Split image data into 60, 20, 20 for training, testing, and cross-validation sets\n",
    "X_train = X[:3]\n",
    "X_cv = X[3]\n",
    "X_test = X[4]\n",
    "\n",
    "#Extract input_shape of a single image: (height, width, channels)\n",
    "#Batch size = 1ipc * 10 classes\n",
    "batch_size, height, width, channels = X_train[0].shape\n",
    "print('Batch_size: ', batch_size, ' Height: ', height, ' Width: ', width, ' Channels: ', channels)\n",
    "\n",
    "#Create list of label tensor objects\n",
    "#Convert PyTorch tensors to TensorFlow tensors\n",
    "y=[]\n",
    "for i in range(5):\n",
    "    numpy_y = input['data'][i][1].numpy()\n",
    "    tf_y = tf.convert_to_tensor(numpy_y, dtype = tf.float32)\n",
    "    y.append(tf_y)\n",
    "\n",
    "#Split labels into 60, 20, 20 for training, testing, and cross-validation sets\n",
    "y_train = y[:3]\n",
    "y_cv = y[3]\n",
    "y_test = y[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "#Set global seed so that results don't vary across runs\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "model_condensed = Sequential(\n",
    "    [\n",
    "    #conv layer 1 (relu)\n",
    "    Conv2D(input_shape = (height, width, channels), filters=6, kernel_size=5, strides=1, padding='same', activation='relu', name='conv1'),\n",
    "    #avg pooling\n",
    "    AveragePooling2D(pool_size=2, strides=2, name='pooling1'),\n",
    "    #conv layer 2 (relu)\n",
    "    Conv2D(filters=16, kernel_size=5, strides=1, padding='valid', activation='relu', name='conv2'),\n",
    "    #avg pooling\n",
    "    AveragePooling2D(pool_size=2, strides=2, name='pooling2'),\n",
    "    #conv layer 3 (relu)\n",
    "    Conv2D(filters=120, kernel_size=5, strides=1, padding='valid', activation='relu', name='conv3'),\n",
    "    #flatten\n",
    "    Flatten(),\n",
    "    #fully connected layer 1 (relu)\n",
    "    Dense(84, activation='relu', name='dense1', kernel_regularizer=tf.keras.regularizers.l2(0.1)),\n",
    "    #fully connected layer 2 (linear)\n",
    "    Dense(10, activation='linear', name='dense2')\n",
    "    ], name='LeNet-5'\n",
    ")\n",
    "# filters are the same as output channel\n",
    "\n",
    "model_condensed.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-2),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 12.0082 - accuracy: 0.1000 - val_loss: 10.3336 - val_accuracy: 0.1000\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 10.3326 - accuracy: 0.1333 - val_loss: 8.7806 - val_accuracy: 0.4000\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 8.7765 - accuracy: 0.4000 - val_loss: 7.1978 - val_accuracy: 0.6000\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.1941 - accuracy: 0.6000 - val_loss: 5.4603 - val_accuracy: 0.9000\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 5.4573 - accuracy: 0.7667 - val_loss: 4.1499 - val_accuracy: 1.0000\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.1429 - accuracy: 1.0000 - val_loss: 3.7516 - val_accuracy: 0.8000\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.7525 - accuracy: 0.8000 - val_loss: 3.9204 - val_accuracy: 0.6000\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.8792 - accuracy: 0.6000 - val_loss: 2.2181 - val_accuracy: 1.0000\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.2278 - accuracy: 1.0000 - val_loss: 2.3736 - val_accuracy: 0.9000\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 2.4113 - accuracy: 0.9000 - val_loss: 2.0817 - val_accuracy: 0.9000\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 2.1082 - accuracy: 0.9000 - val_loss: 1.7311 - val_accuracy: 0.9000\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.7411 - accuracy: 0.9000 - val_loss: 1.5693 - val_accuracy: 1.0000\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.5725 - accuracy: 1.0000 - val_loss: 1.4608 - val_accuracy: 1.0000\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.4625 - accuracy: 1.0000 - val_loss: 1.3285 - val_accuracy: 1.0000\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3286 - accuracy: 1.0000 - val_loss: 1.1717 - val_accuracy: 1.0000\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1703 - accuracy: 1.0000 - val_loss: 1.0388 - val_accuracy: 1.0000\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0377 - accuracy: 1.0000 - val_loss: 0.9647 - val_accuracy: 1.0000\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9642 - accuracy: 1.0000 - val_loss: 0.9283 - val_accuracy: 1.0000\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9280 - accuracy: 1.0000 - val_loss: 0.9063 - val_accuracy: 1.0000\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9060 - accuracy: 1.0000 - val_loss: 0.8889 - val_accuracy: 1.0000\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8887 - accuracy: 1.0000 - val_loss: 0.8708 - val_accuracy: 1.0000\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8706 - accuracy: 1.0000 - val_loss: 0.8499 - val_accuracy: 1.0000\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8497 - accuracy: 1.0000 - val_loss: 0.8252 - val_accuracy: 1.0000\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8248 - accuracy: 1.0000 - val_loss: 0.7964 - val_accuracy: 1.0000\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7960 - accuracy: 1.0000 - val_loss: 0.7636 - val_accuracy: 1.0000\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7633 - accuracy: 1.0000 - val_loss: 0.7272 - val_accuracy: 1.0000\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7270 - accuracy: 1.0000 - val_loss: 0.6883 - val_accuracy: 1.0000\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6882 - accuracy: 1.0000 - val_loss: 0.6480 - val_accuracy: 1.0000\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6479 - accuracy: 1.0000 - val_loss: 0.6069 - val_accuracy: 1.0000\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6068 - accuracy: 1.0000 - val_loss: 0.5657 - val_accuracy: 1.0000\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5656 - accuracy: 1.0000 - val_loss: 0.5252 - val_accuracy: 1.0000\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.5251 - accuracy: 1.0000 - val_loss: 0.4859 - val_accuracy: 1.0000\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4858 - accuracy: 1.0000 - val_loss: 0.4484 - val_accuracy: 1.0000\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4483 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 1.0000\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4129 - accuracy: 1.0000 - val_loss: 0.3799 - val_accuracy: 1.0000\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3799 - accuracy: 1.0000 - val_loss: 0.3494 - val_accuracy: 1.0000\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3493 - accuracy: 1.0000 - val_loss: 0.3215 - val_accuracy: 1.0000\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3215 - accuracy: 1.0000 - val_loss: 0.2963 - val_accuracy: 1.0000\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2963 - accuracy: 1.0000 - val_loss: 0.2735 - val_accuracy: 1.0000\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2734 - accuracy: 1.0000 - val_loss: 0.2531 - val_accuracy: 1.0000\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.2530 - accuracy: 1.0000 - val_loss: 0.2349 - val_accuracy: 1.0000\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2348 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 1.0000\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2187 - accuracy: 1.0000 - val_loss: 0.2044 - val_accuracy: 1.0000\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2043 - accuracy: 1.0000 - val_loss: 0.1916 - val_accuracy: 1.0000\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1914 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 1.0000\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1797 - accuracy: 1.0000 - val_loss: 0.1694 - val_accuracy: 1.0000\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1693 - accuracy: 1.0000 - val_loss: 0.1596 - val_accuracy: 1.0000\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1596 - accuracy: 1.0000 - val_loss: 0.1509 - val_accuracy: 1.0000\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1508 - accuracy: 1.0000 - val_loss: 0.1426 - val_accuracy: 1.0000\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1426 - accuracy: 1.0000 - val_loss: 0.1348 - val_accuracy: 1.0000\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1348 - accuracy: 1.0000 - val_loss: 0.1275 - val_accuracy: 1.0000\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1275 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 1.0000\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1205 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 1.0000\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1138 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 1.0000\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1074 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 1.0000\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1011 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 1.0000\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0952 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 1.0000\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0895 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 1.0000\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0841 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 1.0000\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0791 - accuracy: 1.0000 - val_loss: 0.0744 - val_accuracy: 1.0000\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0744 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 1.0000\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 1.0000\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.0619 - val_accuracy: 1.0000\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0619 - accuracy: 1.0000 - val_loss: 0.0584 - val_accuracy: 1.0000\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.0551 - val_accuracy: 1.0000\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0550 - accuracy: 1.0000 - val_loss: 0.0520 - val_accuracy: 1.0000\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0520 - accuracy: 1.0000 - val_loss: 0.0493 - val_accuracy: 1.0000\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 1.0000\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 0.0446 - val_accuracy: 1.0000\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 1.0000\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0431 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9000\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.1669 - accuracy: 0.9000 - val_loss: 12.1753 - val_accuracy: 0.1000\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 12.1605 - accuracy: 0.1000 - val_loss: 3.7471 - val_accuracy: 0.8000\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.7325 - accuracy: 0.8000 - val_loss: 2.0221 - val_accuracy: 0.8000\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.0293 - accuracy: 0.8000 - val_loss: 1.1498 - val_accuracy: 0.8000\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1571 - accuracy: 0.8000 - val_loss: 0.9516 - val_accuracy: 0.9000\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.9586 - accuracy: 0.9000 - val_loss: 1.1048 - val_accuracy: 0.9000\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1055 - accuracy: 0.9000 - val_loss: 1.3006 - val_accuracy: 0.9000\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.2945 - accuracy: 0.9000 - val_loss: 1.4201 - val_accuracy: 0.9000\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4115 - accuracy: 0.9000 - val_loss: 1.4135 - val_accuracy: 0.9000\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4061 - accuracy: 0.9000 - val_loss: 1.3621 - val_accuracy: 0.9000\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3582 - accuracy: 0.9000 - val_loss: 1.3472 - val_accuracy: 0.9000\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3449 - accuracy: 0.9000 - val_loss: 1.3700 - val_accuracy: 0.9000\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3683 - accuracy: 0.9000 - val_loss: 1.4171 - val_accuracy: 0.9000\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4142 - accuracy: 0.9000 - val_loss: 1.4639 - val_accuracy: 0.9000\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4612 - accuracy: 0.9000 - val_loss: 1.4915 - val_accuracy: 0.9000\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4895 - accuracy: 0.9000 - val_loss: 1.5048 - val_accuracy: 0.9000\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5036 - accuracy: 0.9000 - val_loss: 1.5240 - val_accuracy: 0.9000\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5228 - accuracy: 0.9000 - val_loss: 1.5432 - val_accuracy: 0.9000\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5407 - accuracy: 0.9000 - val_loss: 1.5415 - val_accuracy: 0.9000\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.5390 - accuracy: 0.9000 - val_loss: 1.5251 - val_accuracy: 0.9000\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5235 - accuracy: 0.9000 - val_loss: 1.5035 - val_accuracy: 0.9000\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5029 - accuracy: 0.9000 - val_loss: 1.4809 - val_accuracy: 1.0000\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.4805 - accuracy: 1.0000 - val_loss: 1.4538 - val_accuracy: 1.0000\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.4538 - accuracy: 1.0000 - val_loss: 1.4249 - val_accuracy: 1.0000\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4242 - accuracy: 1.0000 - val_loss: 1.4015 - val_accuracy: 1.0000\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.4001 - accuracy: 1.0000 - val_loss: 1.3766 - val_accuracy: 1.0000\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.3751 - accuracy: 1.0000 - val_loss: 1.3362 - val_accuracy: 1.0000\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.3355 - accuracy: 1.0000 - val_loss: 1.3028 - val_accuracy: 1.0000\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.3026 - accuracy: 1.0000 - val_loss: 1.2722 - val_accuracy: 1.0000\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.2719 - accuracy: 1.0000 - val_loss: 1.2383 - val_accuracy: 1.0000\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2382 - accuracy: 1.0000 - val_loss: 1.2053 - val_accuracy: 1.0000\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.2052 - accuracy: 1.0000 - val_loss: 1.1734 - val_accuracy: 1.0000\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1733 - accuracy: 1.0000 - val_loss: 1.1417 - val_accuracy: 1.0000\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.1416 - accuracy: 1.0000 - val_loss: 1.1100 - val_accuracy: 1.0000\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.1099 - accuracy: 1.0000 - val_loss: 1.0784 - val_accuracy: 1.0000\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0784 - accuracy: 1.0000 - val_loss: 1.0467 - val_accuracy: 1.0000\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0468 - accuracy: 1.0000 - val_loss: 1.0154 - val_accuracy: 1.0000\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0154 - accuracy: 1.0000 - val_loss: 0.9846 - val_accuracy: 1.0000\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9846 - accuracy: 1.0000 - val_loss: 0.9544 - val_accuracy: 1.0000\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9544 - accuracy: 1.0000 - val_loss: 0.9250 - val_accuracy: 1.0000\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9250 - accuracy: 1.0000 - val_loss: 0.8963 - val_accuracy: 1.0000\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8963 - accuracy: 1.0000 - val_loss: 0.8687 - val_accuracy: 1.0000\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8687 - accuracy: 1.0000 - val_loss: 0.8423 - val_accuracy: 1.0000\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8423 - accuracy: 1.0000 - val_loss: 0.8169 - val_accuracy: 1.0000\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8169 - accuracy: 1.0000 - val_loss: 0.7923 - val_accuracy: 1.0000\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7923 - accuracy: 1.0000 - val_loss: 0.7681 - val_accuracy: 1.0000\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.7681 - accuracy: 1.0000 - val_loss: 0.7447 - val_accuracy: 1.0000\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7447 - accuracy: 1.0000 - val_loss: 0.7222 - val_accuracy: 1.0000\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7222 - accuracy: 1.0000 - val_loss: 0.7009 - val_accuracy: 1.0000\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.7009 - accuracy: 1.0000 - val_loss: 0.6805 - val_accuracy: 1.0000\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6804 - accuracy: 1.0000 - val_loss: 0.6607 - val_accuracy: 1.0000\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6606 - accuracy: 1.0000 - val_loss: 0.6414 - val_accuracy: 1.0000\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6414 - accuracy: 1.0000 - val_loss: 0.6228 - val_accuracy: 1.0000\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6228 - accuracy: 1.0000 - val_loss: 0.6049 - val_accuracy: 1.0000\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6049 - accuracy: 1.0000 - val_loss: 0.5878 - val_accuracy: 1.0000\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5878 - accuracy: 1.0000 - val_loss: 0.5715 - val_accuracy: 1.0000\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5715 - accuracy: 1.0000 - val_loss: 0.5555 - val_accuracy: 1.0000\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5556 - accuracy: 1.0000 - val_loss: 0.5402 - val_accuracy: 1.0000\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5402 - accuracy: 1.0000 - val_loss: 0.5254 - val_accuracy: 1.0000\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5254 - accuracy: 1.0000 - val_loss: 0.5112 - val_accuracy: 1.0000\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5112 - accuracy: 1.0000 - val_loss: 0.4975 - val_accuracy: 1.0000\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4975 - accuracy: 1.0000 - val_loss: 0.4843 - val_accuracy: 1.0000\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4843 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 1.0000\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4716 - accuracy: 1.0000 - val_loss: 0.4593 - val_accuracy: 1.0000\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.4593 - accuracy: 1.0000 - val_loss: 0.4475 - val_accuracy: 1.0000\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4474 - accuracy: 1.0000 - val_loss: 0.4360 - val_accuracy: 1.0000\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4360 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 1.0000\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4249 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 1.0000\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4142 - accuracy: 1.0000 - val_loss: 0.4040 - val_accuracy: 1.0000\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4040 - accuracy: 1.0000 - val_loss: 0.3940 - val_accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3940 - accuracy: 1.0000 - val_loss: 0.3843 - val_accuracy: 1.0000\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3843 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 1.0000\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3750 - accuracy: 1.0000 - val_loss: 0.3659 - val_accuracy: 1.0000\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3659 - accuracy: 1.0000 - val_loss: 0.3572 - val_accuracy: 1.0000\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3572 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 1.0000\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3487 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 1.0000\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3405 - accuracy: 1.0000 - val_loss: 0.3326 - val_accuracy: 1.0000\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3326 - accuracy: 1.0000 - val_loss: 0.3248 - val_accuracy: 1.0000\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3248 - accuracy: 1.0000 - val_loss: 0.3173 - val_accuracy: 1.0000\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3173 - accuracy: 1.0000 - val_loss: 0.3101 - val_accuracy: 1.0000\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3101 - accuracy: 1.0000 - val_loss: 0.3032 - val_accuracy: 1.0000\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.3031 - accuracy: 1.0000 - val_loss: 0.2964 - val_accuracy: 1.0000\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2964 - accuracy: 1.0000 - val_loss: 0.2899 - val_accuracy: 1.0000\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2899 - accuracy: 1.0000 - val_loss: 0.2833 - val_accuracy: 1.0000\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2833 - accuracy: 1.0000 - val_loss: 0.2772 - val_accuracy: 1.0000\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2771 - accuracy: 1.0000 - val_loss: 0.2711 - val_accuracy: 1.0000\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2711 - accuracy: 1.0000 - val_loss: 0.2651 - val_accuracy: 1.0000\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2651 - accuracy: 1.0000 - val_loss: 0.2596 - val_accuracy: 1.0000\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2595 - accuracy: 1.0000 - val_loss: 0.2541 - val_accuracy: 1.0000\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2541 - accuracy: 1.0000 - val_loss: 0.2487 - val_accuracy: 1.0000\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2487 - accuracy: 1.0000 - val_loss: 0.2443 - val_accuracy: 1.0000\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2444 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.9000\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4312 - accuracy: 0.9000 - val_loss: 5.9313 - val_accuracy: 0.7000\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.9282 - accuracy: 0.7000 - val_loss: 4.3718 - val_accuracy: 0.6000\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 4.3184 - accuracy: 0.6000 - val_loss: 0.3789 - val_accuracy: 1.0000\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3494 - accuracy: 1.0000 - val_loss: 0.4747 - val_accuracy: 1.0000\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4826 - accuracy: 1.0000 - val_loss: 0.6847 - val_accuracy: 0.9000\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7013 - accuracy: 0.9000 - val_loss: 0.6484 - val_accuracy: 1.0000\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6506 - accuracy: 1.0000 - val_loss: 0.6533 - val_accuracy: 1.0000\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6504 - accuracy: 1.0000 - val_loss: 0.7310 - val_accuracy: 1.0000\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7271 - accuracy: 1.0000 - val_loss: 0.8150 - val_accuracy: 1.0000\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8107 - accuracy: 1.0000 - val_loss: 0.8894 - val_accuracy: 1.0000\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8845 - accuracy: 1.0000 - val_loss: 0.9536 - val_accuracy: 1.0000\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9484 - accuracy: 1.0000 - val_loss: 0.9994 - val_accuracy: 1.0000\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9956 - accuracy: 1.0000 - val_loss: 1.0361 - val_accuracy: 1.0000\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0326 - accuracy: 1.0000 - val_loss: 1.0638 - val_accuracy: 1.0000\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0613 - accuracy: 1.0000 - val_loss: 1.0841 - val_accuracy: 1.0000\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.0828 - accuracy: 1.0000 - val_loss: 1.0987 - val_accuracy: 1.0000\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0981 - accuracy: 1.0000 - val_loss: 1.1067 - val_accuracy: 1.0000\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1063 - accuracy: 1.0000 - val_loss: 1.1082 - val_accuracy: 1.0000\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1080 - accuracy: 1.0000 - val_loss: 1.1039 - val_accuracy: 1.0000\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1038 - accuracy: 1.0000 - val_loss: 1.0946 - val_accuracy: 1.0000\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0946 - accuracy: 1.0000 - val_loss: 1.0811 - val_accuracy: 1.0000\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0810 - accuracy: 1.0000 - val_loss: 1.0638 - val_accuracy: 1.0000\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0638 - accuracy: 1.0000 - val_loss: 1.0437 - val_accuracy: 1.0000\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.0435 - accuracy: 1.0000 - val_loss: 1.0212 - val_accuracy: 1.0000\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.0210 - accuracy: 1.0000 - val_loss: 0.9971 - val_accuracy: 1.0000\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.9968 - accuracy: 1.0000 - val_loss: 0.9717 - val_accuracy: 1.0000\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9714 - accuracy: 1.0000 - val_loss: 0.9456 - val_accuracy: 1.0000\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.9453 - accuracy: 1.0000 - val_loss: 0.9193 - val_accuracy: 1.0000\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.9188 - accuracy: 1.0000 - val_loss: 0.8930 - val_accuracy: 1.0000\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8923 - accuracy: 1.0000 - val_loss: 0.8670 - val_accuracy: 1.0000\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.8662 - accuracy: 1.0000 - val_loss: 0.8410 - val_accuracy: 1.0000\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8401 - accuracy: 1.0000 - val_loss: 0.8148 - val_accuracy: 1.0000\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.8140 - accuracy: 1.0000 - val_loss: 0.7888 - val_accuracy: 1.0000\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7882 - accuracy: 1.0000 - val_loss: 0.7635 - val_accuracy: 1.0000\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7631 - accuracy: 1.0000 - val_loss: 0.7389 - val_accuracy: 1.0000\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7385 - accuracy: 1.0000 - val_loss: 0.7148 - val_accuracy: 1.0000\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7145 - accuracy: 1.0000 - val_loss: 0.6914 - val_accuracy: 1.0000\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6911 - accuracy: 1.0000 - val_loss: 0.6687 - val_accuracy: 1.0000\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6686 - accuracy: 1.0000 - val_loss: 0.6471 - val_accuracy: 1.0000\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6468 - accuracy: 1.0000 - val_loss: 0.6261 - val_accuracy: 1.0000\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6259 - accuracy: 1.0000 - val_loss: 0.6060 - val_accuracy: 1.0000\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6058 - accuracy: 1.0000 - val_loss: 0.5865 - val_accuracy: 1.0000\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5863 - accuracy: 1.0000 - val_loss: 0.5676 - val_accuracy: 1.0000\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5675 - accuracy: 1.0000 - val_loss: 0.5494 - val_accuracy: 1.0000\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5493 - accuracy: 1.0000 - val_loss: 0.5319 - val_accuracy: 1.0000\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5318 - accuracy: 1.0000 - val_loss: 0.5150 - val_accuracy: 1.0000\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5149 - accuracy: 1.0000 - val_loss: 0.4988 - val_accuracy: 1.0000\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4987 - accuracy: 1.0000 - val_loss: 0.4832 - val_accuracy: 1.0000\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4831 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 1.0000\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4681 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 1.0000\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4536 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 1.0000\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4397 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 1.0000\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4264 - accuracy: 1.0000 - val_loss: 0.4138 - val_accuracy: 1.0000\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4136 - accuracy: 1.0000 - val_loss: 0.4014 - val_accuracy: 1.0000\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4013 - accuracy: 1.0000 - val_loss: 0.3896 - val_accuracy: 1.0000\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3894 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 1.0000\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3779 - accuracy: 1.0000 - val_loss: 0.3671 - val_accuracy: 1.0000\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3669 - accuracy: 1.0000 - val_loss: 0.3565 - val_accuracy: 1.0000\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3564 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 1.0000\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3462 - accuracy: 1.0000 - val_loss: 0.3367 - val_accuracy: 1.0000\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3365 - accuracy: 1.0000 - val_loss: 0.3273 - val_accuracy: 1.0000\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3271 - accuracy: 1.0000 - val_loss: 0.3182 - val_accuracy: 1.0000\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3181 - accuracy: 1.0000 - val_loss: 0.3095 - val_accuracy: 1.0000\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3094 - accuracy: 1.0000 - val_loss: 0.3012 - val_accuracy: 1.0000\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3010 - accuracy: 1.0000 - val_loss: 0.2931 - val_accuracy: 1.0000\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2929 - accuracy: 1.0000 - val_loss: 0.2853 - val_accuracy: 1.0000\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2852 - accuracy: 1.0000 - val_loss: 0.2778 - val_accuracy: 1.0000\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2777 - accuracy: 1.0000 - val_loss: 0.2706 - val_accuracy: 1.0000\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2705 - accuracy: 1.0000 - val_loss: 0.2636 - val_accuracy: 1.0000\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2635 - accuracy: 1.0000 - val_loss: 0.2569 - val_accuracy: 1.0000\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2568 - accuracy: 1.0000 - val_loss: 0.2504 - val_accuracy: 1.0000\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2503 - accuracy: 1.0000 - val_loss: 0.2441 - val_accuracy: 1.0000\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.2440 - accuracy: 1.0000 - val_loss: 0.2381 - val_accuracy: 1.0000\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.2380 - accuracy: 1.0000 - val_loss: 0.2322 - val_accuracy: 1.0000\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2321 - accuracy: 1.0000 - val_loss: 0.2266 - val_accuracy: 1.0000\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2265 - accuracy: 1.0000 - val_loss: 0.2211 - val_accuracy: 1.0000\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2210 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 1.0000\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2157 - accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 1.0000\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2106 - accuracy: 1.0000 - val_loss: 0.2058 - val_accuracy: 1.0000\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2057 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 1.0000\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2009 - accuracy: 1.0000 - val_loss: 0.1964 - val_accuracy: 1.0000\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1963 - accuracy: 1.0000 - val_loss: 0.1919 - val_accuracy: 1.0000\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1918 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 1.0000\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1874 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 1.0000\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1832 - accuracy: 1.0000 - val_loss: 0.1793 - val_accuracy: 1.0000\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1792 - accuracy: 1.0000 - val_loss: 0.1753 - val_accuracy: 1.0000\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1752 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 1.0000\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1714 - accuracy: 1.0000 - val_loss: 0.1678 - val_accuracy: 1.0000\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1677 - accuracy: 1.0000 - val_loss: 0.1642 - val_accuracy: 1.0000\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1640 - accuracy: 1.0000 - val_loss: 0.1607 - val_accuracy: 1.0000\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1606 - accuracy: 1.0000 - val_loss: 0.1573 - val_accuracy: 1.0000\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1572 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 1.0000\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1538 - accuracy: 1.0000 - val_loss: 0.1508 - val_accuracy: 1.0000\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1506 - accuracy: 1.0000 - val_loss: 0.1476 - val_accuracy: 1.0000\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1475 - accuracy: 1.0000 - val_loss: 0.1446 - val_accuracy: 1.0000\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1445 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 1.0000\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1415 - accuracy: 1.0000 - val_loss: 0.1388 - val_accuracy: 1.0000\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1386 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 1.0000\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1359 - accuracy: 1.0000 - val_loss: 0.1333 - val_accuracy: 1.0000\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1332 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 1.0000\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1305 - accuracy: 1.0000 - val_loss: 0.1281 - val_accuracy: 1.0000\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1280 - accuracy: 1.0000 - val_loss: 0.1256 - val_accuracy: 1.0000\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1254 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1230 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1206 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 1.0000\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.1183 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 1.0000\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.1161 - accuracy: 1.0000 - val_loss: 0.1140 - val_accuracy: 1.0000\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1138 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1117 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1096 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1076 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 1.0000\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1056 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1037 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1018 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1000 - accuracy: 1.0000 - val_loss: 0.0983 - val_accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0982 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 1.0000\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0964 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 1.0000\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0947 - accuracy: 1.0000 - val_loss: 0.0931 - val_accuracy: 1.0000\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0930 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 1.0000\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0914 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0898 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 1.0000\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0882 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 1.0000\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0867 - accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 1.0000\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0852 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 1.0000\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0838 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 1.0000\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 1.0000\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0810 - accuracy: 1.0000 - val_loss: 0.0797 - val_accuracy: 1.0000\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 1.0000\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0783 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 1.0000\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0770 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 1.0000\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0757 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0745 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 1.0000\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0720 - accuracy: 1.0000 - val_loss: 0.0710 - val_accuracy: 1.0000\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 0.0698 - val_accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0697 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
      "Took 5.81723 seconds\n"
     ]
    }
   ],
   "source": [
    "#Combine input tensors since model expects 1 input tensor (simplifies process so we can treat input as single entity instead of multiple for each tensor)\n",
    "#Initialize lists so that their values are reset every time the Jupyter notebook is run\n",
    "X_train_combined=[]\n",
    "y_train_combined=[]\n",
    "X_temp=X_train[0]\n",
    "y_temp=y_train[0]\n",
    "\n",
    "#Essentially a running sum where you add the ith + 1 element in each iteration until reaching the end of the list\n",
    "for i in range(len(X_train)):\n",
    "    try:\n",
    "        X_temp = np.concatenate((X_temp, X_train[i+1]), axis=0)\n",
    "        y_temp = np.concatenate((y_temp, y_train[i+1]), axis=0)\n",
    "    except:\n",
    "        X_train_combined = X_temp\n",
    "        y_train_combined = y_temp\n",
    "        break\n",
    "\n",
    "start = time()\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model_condensed.fit(X_train_combined, y_train_combined, epochs=300, validation_data=(X_cv, y_cv))\n",
    "\n",
    "#Display duration\n",
    "duration_1 = time() - start\n",
    "print(f'Took {duration_1:.5f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "Training Accuracy         (regularized, 1ipc): 1.0000000\n",
      "Cross Validation Accuracy (regularized, 1ipc): 1.0000000\n",
      "Test Accuracy             (regularized, 1ipc): 1.0000000\n"
     ]
    }
   ],
   "source": [
    "#make a model for plotting routines to call\n",
    "model_predict = lambda Xl: np.argmax(tf.nn.softmax(model_condensed.predict(Xl)).numpy(),axis=1)\n",
    "\n",
    "training_cerr_1 = eval_cat_err(y_train_combined, model_predict(X_train_combined))\n",
    "cv_cerr_1 = eval_cat_err(y_cv, model_predict(X_cv))\n",
    "test_cerr_1 = eval_cat_err(y_test, model_predict(X_test))\n",
    "print(f\"Training Accuracy         (regularized, 1ipc): {1-training_cerr_1:0.7f}\" )\n",
    "print(f\"Cross Validation Accuracy (regularized, 1ipc): {1-cv_cerr_1:0.7f}\" )\n",
    "print(f\"Test Accuracy             (regularized, 1ipc): {1-test_cerr_1:0.7f}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Images per Class (5 samples = 500 images total): 300 training, 100 cv, 100 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_size:  100  Height:  28  Width:  28  Channels:  1\n"
     ]
    }
   ],
   "source": [
    "input_10 = torch.load('<--filepath-->')      #<------Use filepath to the 10ipc .pt file\n",
    "\n",
    "# print(input_10['data'][0])\n",
    "\n",
    "#Create list of tensor objects without labels\n",
    "X_10=[]\n",
    "for i in range(5):\n",
    "    permuted = input_10['data'][i][0].permute(0, 2, 3, 1)\n",
    "    numpy_X = permuted.numpy()\n",
    "    tf_X = tf.convert_to_tensor(numpy_X, dtype = tf.float32)\n",
    "    X_10.append(tf_X)\n",
    "\n",
    "#Split image data into 60, 20, 20 for training, testing, and cross-validation sets\n",
    "X10_train = X_10[:3]\n",
    "X10_cv = X_10[3]\n",
    "X10_test = X_10[4]\n",
    "\n",
    "#Batch size = 10ipc * 10 classes\n",
    "batch_size_10, height_10, width_10, channels_10 = X10_train[0].shape\n",
    "print('Batch_size: ', batch_size_10, ' Height: ', height_10, ' Width: ', width_10, ' Channels: ', channels_10)\n",
    "\n",
    "#Create list of label tensor objects\n",
    "y_10=[]\n",
    "for i in range(5):\n",
    "    numpy_y = input_10['data'][i][1].numpy()\n",
    "    tf_y = tf.convert_to_tensor(numpy_y, dtype = tf.float32)\n",
    "    y_10.append(tf_y)\n",
    "\n",
    "#Split labels into 60, 20, 20 for training, testing, and cross-validation sets\n",
    "y10_train = y_10[:3]\n",
    "y10_cv = y_10[3]\n",
    "y10_test = y_10[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To prevent an excessive messages when running\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "#Set global seed so that results don't vary across runs\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "model_10_condensed = Sequential(\n",
    "    [\n",
    "    #conv layer 1 (relu)\n",
    "    Conv2D(input_shape = (height_10, width_10, channels_10), filters=6, kernel_size=5, strides=1, padding='same', activation='relu', name='conv1'),\n",
    "    #avg pooling\n",
    "    AveragePooling2D(pool_size=2, strides=2, name='pooling1'),\n",
    "    #conv layer 2 (relu)\n",
    "    Conv2D(filters=16, kernel_size=5, strides=1, padding='valid', activation='relu', name='conv2'),\n",
    "    #avg pooling\n",
    "    AveragePooling2D(pool_size=2, strides=2, name='pooling2'),\n",
    "    #conv layer 3 (relu)\n",
    "    Conv2D(filters=120, kernel_size=5, strides=1, padding='valid', activation='relu', name='conv3'),\n",
    "    #flatten\n",
    "    Flatten(),\n",
    "    #fully connected layer 1 (relu)\n",
    "    Dense(84, activation='relu', name='dense1', kernel_regularizer=tf.keras.regularizers.l2(0.1)),\n",
    "    #fully connected layer 2 (linear)\n",
    "    Dense(10, activation='linear', name='dense2')\n",
    "    ], name='LeNet-5'\n",
    ")\n",
    "# filters are the same as output channel\n",
    "\n",
    "model_10_condensed.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=1e-2),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0192 - accuracy: 0.9967 - val_loss: 0.1270 - val_accuracy: 0.9600\n",
      "Epoch 2/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0189 - accuracy: 0.9967 - val_loss: 0.1192 - val_accuracy: 0.9700\n",
      "Epoch 3/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0183 - accuracy: 0.9967 - val_loss: 0.1188 - val_accuracy: 0.9700\n",
      "Epoch 4/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0176 - accuracy: 0.9967 - val_loss: 0.1288 - val_accuracy: 0.9700\n",
      "Epoch 5/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9967 - val_loss: 0.1259 - val_accuracy: 0.9800\n",
      "Epoch 6/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0173 - accuracy: 0.9967 - val_loss: 0.1198 - val_accuracy: 0.9800\n",
      "Epoch 7/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0154 - accuracy: 0.9967 - val_loss: 0.1186 - val_accuracy: 0.9800\n",
      "Epoch 8/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0164 - accuracy: 0.9967 - val_loss: 0.1191 - val_accuracy: 0.9800\n",
      "Epoch 9/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0156 - accuracy: 0.9967 - val_loss: 0.1158 - val_accuracy: 0.9800\n",
      "Epoch 10/300\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0161 - accuracy: 0.9967 - val_loss: 0.1141 - val_accuracy: 0.9900\n",
      "Epoch 11/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0147 - accuracy: 0.9967 - val_loss: 0.1080 - val_accuracy: 0.9900\n",
      "Epoch 12/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0125 - accuracy: 0.9967 - val_loss: 0.1102 - val_accuracy: 0.9900\n",
      "Epoch 13/300\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.1087 - val_accuracy: 0.9800\n",
      "Epoch 14/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.1065 - val_accuracy: 0.9800\n",
      "Epoch 15/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0089 - accuracy: 0.9967 - val_loss: 0.1035 - val_accuracy: 0.9800\n",
      "Epoch 16/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1022 - val_accuracy: 0.9800\n",
      "Epoch 17/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9800\n",
      "Epoch 18/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9800\n",
      "Epoch 19/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9900\n",
      "Epoch 20/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9800\n",
      "Epoch 21/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9800\n",
      "Epoch 22/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9800\n",
      "Epoch 23/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0991 - val_accuracy: 0.9900\n",
      "Epoch 24/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9800\n",
      "Epoch 25/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9800\n",
      "Epoch 26/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9800\n",
      "Epoch 27/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9900\n",
      "Epoch 28/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9800\n",
      "Epoch 29/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9800\n",
      "Epoch 30/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9800\n",
      "Epoch 31/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9900\n",
      "Epoch 32/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9800\n",
      "Epoch 33/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9800\n",
      "Epoch 34/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9900\n",
      "Epoch 35/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9800\n",
      "Epoch 36/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9800\n",
      "Epoch 37/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9800\n",
      "Epoch 38/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9900\n",
      "Epoch 39/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9900\n",
      "Epoch 40/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9800\n",
      "Epoch 41/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9800\n",
      "Epoch 42/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9900\n",
      "Epoch 43/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9800\n",
      "Epoch 44/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9800\n",
      "Epoch 45/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0893 - val_accuracy: 0.9900\n",
      "Epoch 46/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0896 - val_accuracy: 0.9800\n",
      "Epoch 47/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9800\n",
      "Epoch 48/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1828 - accuracy: 0.9633 - val_loss: 0.3178 - val_accuracy: 0.9600\n",
      "Epoch 49/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3108 - accuracy: 0.9700 - val_loss: 1.1939 - val_accuracy: 0.9300\n",
      "Epoch 50/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.7837 - accuracy: 0.9633 - val_loss: 1.3355 - val_accuracy: 0.8800\n",
      "Epoch 51/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.1422 - accuracy: 0.9167 - val_loss: 1.0238 - val_accuracy: 0.9400\n",
      "Epoch 52/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0269 - accuracy: 0.9500 - val_loss: 1.4391 - val_accuracy: 0.8700\n",
      "Epoch 53/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 1.0132 - accuracy: 0.9533 - val_loss: 1.8238 - val_accuracy: 0.8800\n",
      "Epoch 54/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.8941 - accuracy: 0.9500 - val_loss: 1.0375 - val_accuracy: 0.8900\n",
      "Epoch 55/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.9241 - accuracy: 0.9567 - val_loss: 0.9422 - val_accuracy: 0.8900\n",
      "Epoch 56/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.6699 - accuracy: 0.9300 - val_loss: 0.8585 - val_accuracy: 0.8900\n",
      "Epoch 57/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5613 - accuracy: 0.9567 - val_loss: 0.8081 - val_accuracy: 0.9000\n",
      "Epoch 58/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.9800 - val_loss: 0.7552 - val_accuracy: 0.9300\n",
      "Epoch 59/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2821 - accuracy: 0.9900 - val_loss: 0.8182 - val_accuracy: 0.9100\n",
      "Epoch 60/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1925 - accuracy: 0.9967 - val_loss: 0.7665 - val_accuracy: 0.9100\n",
      "Epoch 61/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1417 - accuracy: 0.9967 - val_loss: 0.6799 - val_accuracy: 0.9200\n",
      "Epoch 62/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1064 - accuracy: 1.0000 - val_loss: 0.6085 - val_accuracy: 0.9100\n",
      "Epoch 63/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.9200\n",
      "Epoch 64/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0656 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.9200\n",
      "Epoch 65/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0532 - accuracy: 1.0000 - val_loss: 0.3884 - val_accuracy: 0.9200\n",
      "Epoch 66/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.9300\n",
      "Epoch 67/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 0.3233 - val_accuracy: 0.9300\n",
      "Epoch 68/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 0.2983 - val_accuracy: 0.9400\n",
      "Epoch 69/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 0.2804 - val_accuracy: 0.9400\n",
      "Epoch 70/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 0.2554 - val_accuracy: 0.9400\n",
      "Epoch 71/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9400\n",
      "Epoch 72/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9300\n",
      "Epoch 73/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.2343 - val_accuracy: 0.9300\n",
      "Epoch 74/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9300\n",
      "Epoch 75/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.2144 - val_accuracy: 0.9300\n",
      "Epoch 76/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.2191 - val_accuracy: 0.9300\n",
      "Epoch 77/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9300\n",
      "Epoch 78/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.2057 - val_accuracy: 0.9300\n",
      "Epoch 79/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.2010 - val_accuracy: 0.9300\n",
      "Epoch 80/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 0.2026 - val_accuracy: 0.9300\n",
      "Epoch 81/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.2014 - val_accuracy: 0.9300\n",
      "Epoch 82/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1986 - val_accuracy: 0.9400\n",
      "Epoch 83/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.2041 - val_accuracy: 0.9300\n",
      "Epoch 84/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.1974 - val_accuracy: 0.9400\n",
      "Epoch 85/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1994 - val_accuracy: 0.9400\n",
      "Epoch 86/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1875 - val_accuracy: 0.9400\n",
      "Epoch 87/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.1980 - val_accuracy: 0.9400\n",
      "Epoch 88/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9400\n",
      "Epoch 89/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.1951 - val_accuracy: 0.9400\n",
      "Epoch 90/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1750 - val_accuracy: 0.9400\n",
      "Epoch 91/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1847 - val_accuracy: 0.9400\n",
      "Epoch 92/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1942 - val_accuracy: 0.9400\n",
      "Epoch 93/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1910 - val_accuracy: 0.9400\n",
      "Epoch 94/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.1925 - val_accuracy: 0.9400\n",
      "Epoch 95/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1850 - val_accuracy: 0.9400\n",
      "Epoch 96/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1906 - val_accuracy: 0.9400\n",
      "Epoch 97/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1930 - val_accuracy: 0.9400\n",
      "Epoch 98/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.1943 - val_accuracy: 0.9400\n",
      "Epoch 99/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9400\n",
      "Epoch 100/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1895 - val_accuracy: 0.9400\n",
      "Epoch 101/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1861 - val_accuracy: 0.9400\n",
      "Epoch 102/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 0.9400\n",
      "Epoch 103/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.1860 - val_accuracy: 0.9400\n",
      "Epoch 104/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9400\n",
      "Epoch 105/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.1946 - val_accuracy: 0.9400\n",
      "Epoch 106/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1833 - val_accuracy: 0.9400\n",
      "Epoch 107/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1874 - val_accuracy: 0.9400\n",
      "Epoch 108/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1868 - val_accuracy: 0.9400\n",
      "Epoch 109/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1810 - val_accuracy: 0.9400\n",
      "Epoch 110/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1806 - val_accuracy: 0.9400\n",
      "Epoch 111/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1828 - val_accuracy: 0.9400\n",
      "Epoch 112/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1858 - val_accuracy: 0.9400\n",
      "Epoch 113/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1779 - val_accuracy: 0.9400\n",
      "Epoch 114/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1765 - val_accuracy: 0.9400\n",
      "Epoch 115/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1752 - val_accuracy: 0.9400\n",
      "Epoch 116/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1843 - val_accuracy: 0.9400\n",
      "Epoch 117/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.1724 - val_accuracy: 0.9400\n",
      "Epoch 118/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1715 - val_accuracy: 0.9400\n",
      "Epoch 119/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1772 - val_accuracy: 0.9400\n",
      "Epoch 120/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1658 - val_accuracy: 0.9400\n",
      "Epoch 121/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1651 - val_accuracy: 0.9400\n",
      "Epoch 122/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1718 - val_accuracy: 0.9400\n",
      "Epoch 123/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1616 - val_accuracy: 0.9400\n",
      "Epoch 124/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1706 - val_accuracy: 0.9400\n",
      "Epoch 125/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1670 - val_accuracy: 0.9400\n",
      "Epoch 126/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.1625 - val_accuracy: 0.9400\n",
      "Epoch 127/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1702 - val_accuracy: 0.9400\n",
      "Epoch 128/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.1664 - val_accuracy: 0.9400\n",
      "Epoch 129/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1639 - val_accuracy: 0.9400\n",
      "Epoch 130/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1590 - val_accuracy: 0.9400\n",
      "Epoch 131/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.1594 - val_accuracy: 0.9400\n",
      "Epoch 132/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1609 - val_accuracy: 0.9400\n",
      "Epoch 133/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1553 - val_accuracy: 0.9400\n",
      "Epoch 134/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1608 - val_accuracy: 0.9400\n",
      "Epoch 135/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1494 - val_accuracy: 0.9500\n",
      "Epoch 136/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1617 - val_accuracy: 0.9400\n",
      "Epoch 137/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9400\n",
      "Epoch 138/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9400\n",
      "Epoch 139/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1540 - val_accuracy: 0.9400\n",
      "Epoch 140/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1532 - val_accuracy: 0.9400\n",
      "Epoch 141/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1498 - val_accuracy: 0.9400\n",
      "Epoch 142/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1564 - val_accuracy: 0.9400\n",
      "Epoch 143/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1440 - val_accuracy: 0.9500\n",
      "Epoch 144/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 0.9400\n",
      "Epoch 145/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 0.9500\n",
      "Epoch 146/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1487 - val_accuracy: 0.9400\n",
      "Epoch 147/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9500\n",
      "Epoch 148/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1468 - val_accuracy: 0.9500\n",
      "Epoch 149/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1457 - val_accuracy: 0.9500\n",
      "Epoch 150/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9500\n",
      "Epoch 151/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1494 - val_accuracy: 0.9400\n",
      "Epoch 152/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9500\n",
      "Epoch 153/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1447 - val_accuracy: 0.9500\n",
      "Epoch 154/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1465 - val_accuracy: 0.9500\n",
      "Epoch 155/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1331 - val_accuracy: 0.9500\n",
      "Epoch 156/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9500\n",
      "Epoch 157/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1432 - val_accuracy: 0.9400\n",
      "Epoch 158/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1365 - val_accuracy: 0.9500\n",
      "Epoch 159/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9400\n",
      "Epoch 160/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9500\n",
      "Epoch 161/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9400\n",
      "Epoch 162/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 0.9500\n",
      "Epoch 163/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9500\n",
      "Epoch 164/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9500\n",
      "Epoch 165/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 0.9500\n",
      "Epoch 166/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9500\n",
      "Epoch 167/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1363 - val_accuracy: 0.9500\n",
      "Epoch 168/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1319 - val_accuracy: 0.9500\n",
      "Epoch 169/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1357 - val_accuracy: 0.9500\n",
      "Epoch 170/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1244 - val_accuracy: 0.9500\n",
      "Epoch 171/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1353 - val_accuracy: 0.9500\n",
      "Epoch 172/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 0.9500\n",
      "Epoch 173/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1323 - val_accuracy: 0.9500\n",
      "Epoch 174/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1272 - val_accuracy: 0.9500\n",
      "Epoch 175/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9500\n",
      "Epoch 176/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1297 - val_accuracy: 0.9500\n",
      "Epoch 177/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9500\n",
      "Epoch 178/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1264 - val_accuracy: 0.9500\n",
      "Epoch 179/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1284 - val_accuracy: 0.9500\n",
      "Epoch 180/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9500\n",
      "Epoch 181/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1308 - val_accuracy: 0.9500\n",
      "Epoch 182/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1270 - val_accuracy: 0.9500\n",
      "Epoch 183/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1239 - val_accuracy: 0.9500\n",
      "Epoch 184/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9500\n",
      "Epoch 185/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9500\n",
      "Epoch 186/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 0.9500\n",
      "Epoch 187/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9500\n",
      "Epoch 188/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9500\n",
      "Epoch 189/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1141 - val_accuracy: 0.9500\n",
      "Epoch 190/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1225 - val_accuracy: 0.9500\n",
      "Epoch 191/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9500\n",
      "Epoch 192/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9500\n",
      "Epoch 193/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9500\n",
      "Epoch 194/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9500\n",
      "Epoch 195/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9500\n",
      "Epoch 196/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9500\n",
      "Epoch 197/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1191 - val_accuracy: 0.9500\n",
      "Epoch 198/300\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9500\n",
      "Epoch 199/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1320 - val_accuracy: 0.9400\n",
      "Epoch 200/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 0.9600\n",
      "Epoch 201/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9500\n",
      "Epoch 202/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1216 - val_accuracy: 0.9500\n",
      "Epoch 203/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9500\n",
      "Epoch 204/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1229 - val_accuracy: 0.9500\n",
      "Epoch 205/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9500\n",
      "Epoch 206/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1123 - val_accuracy: 0.9500\n",
      "Epoch 207/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9500\n",
      "Epoch 208/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9500\n",
      "Epoch 209/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1109 - val_accuracy: 0.9500\n",
      "Epoch 210/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1123 - val_accuracy: 0.9500\n",
      "Epoch 211/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9500\n",
      "Epoch 212/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9500\n",
      "Epoch 213/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9600\n",
      "Epoch 214/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 0.9500\n",
      "Epoch 215/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9600\n",
      "Epoch 216/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1153 - val_accuracy: 0.9500\n",
      "Epoch 217/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0916 - val_accuracy: 0.9500\n",
      "Epoch 218/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9500\n",
      "Epoch 219/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9600\n",
      "Epoch 220/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9600\n",
      "Epoch 221/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9600\n",
      "Epoch 222/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1143 - val_accuracy: 0.9500\n",
      "Epoch 223/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9600\n",
      "Epoch 224/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9700\n",
      "Epoch 225/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9600\n",
      "Epoch 226/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9700\n",
      "Epoch 227/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1250 - val_accuracy: 0.9500\n",
      "Epoch 228/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9600\n",
      "Epoch 229/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9600\n",
      "Epoch 230/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9600\n",
      "Epoch 231/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9500\n",
      "Epoch 232/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9400\n",
      "Epoch 233/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9500\n",
      "Epoch 234/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9500\n",
      "Epoch 235/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 0.9600\n",
      "Epoch 236/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9500\n",
      "Epoch 237/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9700\n",
      "Epoch 238/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9500\n",
      "Epoch 239/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9600\n",
      "Epoch 240/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9500\n",
      "Epoch 241/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0957 - val_accuracy: 0.9600\n",
      "Epoch 242/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9500\n",
      "Epoch 243/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9500\n",
      "Epoch 244/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9700\n",
      "Epoch 245/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9600\n",
      "Epoch 246/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9600\n",
      "Epoch 247/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9600\n",
      "Epoch 248/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9500\n",
      "Epoch 249/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 0.9700\n",
      "Epoch 250/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9500\n",
      "Epoch 251/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9500\n",
      "Epoch 252/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9600\n",
      "Epoch 253/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0840 - val_accuracy: 0.9500\n",
      "Epoch 254/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9600\n",
      "Epoch 255/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.9400\n",
      "Epoch 256/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5618 - accuracy: 0.9433 - val_loss: 1.4804 - val_accuracy: 0.9200\n",
      "Epoch 257/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0825 - accuracy: 0.9367 - val_loss: 2.9111 - val_accuracy: 0.8500\n",
      "Epoch 258/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.9251 - accuracy: 0.8967 - val_loss: 3.9926 - val_accuracy: 0.8200\n",
      "Epoch 259/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3.4329 - accuracy: 0.7500 - val_loss: 3.7460 - val_accuracy: 0.5900\n",
      "Epoch 260/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 3.4688 - accuracy: 0.5333 - val_loss: 3.2158 - val_accuracy: 0.5000\n",
      "Epoch 261/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2.5795 - accuracy: 0.5667 - val_loss: 2.3804 - val_accuracy: 0.6200\n",
      "Epoch 262/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 2.0567 - accuracy: 0.7267 - val_loss: 2.0864 - val_accuracy: 0.7200\n",
      "Epoch 263/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.6903 - accuracy: 0.7367 - val_loss: 1.5606 - val_accuracy: 0.7000\n",
      "Epoch 264/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.3278 - accuracy: 0.7533 - val_loss: 1.4218 - val_accuracy: 0.7500\n",
      "Epoch 265/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0682 - accuracy: 0.8967 - val_loss: 1.0994 - val_accuracy: 0.8700\n",
      "Epoch 266/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.8097 - accuracy: 0.9033 - val_loss: 1.3457 - val_accuracy: 0.8600\n",
      "Epoch 267/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.6626 - accuracy: 0.9367 - val_loss: 1.0351 - val_accuracy: 0.8700\n",
      "Epoch 268/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5446 - accuracy: 0.9633 - val_loss: 0.9971 - val_accuracy: 0.8800\n",
      "Epoch 269/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5182 - accuracy: 0.9500 - val_loss: 0.7234 - val_accuracy: 0.8900\n",
      "Epoch 270/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4268 - accuracy: 0.9533 - val_loss: 0.7794 - val_accuracy: 0.8900\n",
      "Epoch 271/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.9733 - val_loss: 0.8945 - val_accuracy: 0.9200\n",
      "Epoch 272/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.5351 - accuracy: 0.9833 - val_loss: 0.9137 - val_accuracy: 0.9200\n",
      "Epoch 273/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.5044 - accuracy: 0.9867 - val_loss: 0.7237 - val_accuracy: 0.9100\n",
      "Epoch 274/300\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4266 - accuracy: 0.9900 - val_loss: 0.6184 - val_accuracy: 0.9400\n",
      "Epoch 275/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.3506 - accuracy: 0.9900 - val_loss: 0.5607 - val_accuracy: 0.9200\n",
      "Epoch 276/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2686 - accuracy: 0.9933 - val_loss: 0.5532 - val_accuracy: 0.9200\n",
      "Epoch 277/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.2172 - accuracy: 0.9967 - val_loss: 0.4882 - val_accuracy: 0.9200\n",
      "Epoch 278/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1804 - accuracy: 0.9967 - val_loss: 0.4704 - val_accuracy: 0.9200\n",
      "Epoch 279/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1536 - accuracy: 0.9967 - val_loss: 0.4543 - val_accuracy: 0.9200\n",
      "Epoch 280/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1335 - accuracy: 0.9967 - val_loss: 0.4595 - val_accuracy: 0.9200\n",
      "Epoch 281/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1178 - accuracy: 0.9967 - val_loss: 0.4502 - val_accuracy: 0.9200\n",
      "Epoch 282/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.1053 - accuracy: 0.9967 - val_loss: 0.4307 - val_accuracy: 0.9200\n",
      "Epoch 283/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0960 - accuracy: 0.9967 - val_loss: 0.4303 - val_accuracy: 0.9100\n",
      "Epoch 284/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 0.9967 - val_loss: 0.4097 - val_accuracy: 0.9200\n",
      "Epoch 285/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0820 - accuracy: 0.9967 - val_loss: 0.4894 - val_accuracy: 0.9200\n",
      "Epoch 286/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0752 - accuracy: 0.9967 - val_loss: 0.4019 - val_accuracy: 0.9200\n",
      "Epoch 287/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.9967 - val_loss: 0.3853 - val_accuracy: 0.9200\n",
      "Epoch 288/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0640 - accuracy: 0.9967 - val_loss: 0.3863 - val_accuracy: 0.9200\n",
      "Epoch 289/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0594 - accuracy: 0.9967 - val_loss: 0.3848 - val_accuracy: 0.9200\n",
      "Epoch 290/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0559 - accuracy: 0.9967 - val_loss: 0.3996 - val_accuracy: 0.9200\n",
      "Epoch 291/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0526 - accuracy: 0.9967 - val_loss: 0.3729 - val_accuracy: 0.9200\n",
      "Epoch 292/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.9967 - val_loss: 0.3684 - val_accuracy: 0.9200\n",
      "Epoch 293/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0469 - accuracy: 0.9967 - val_loss: 0.3691 - val_accuracy: 0.9200\n",
      "Epoch 294/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 0.9967 - val_loss: 0.3536 - val_accuracy: 0.9200\n",
      "Epoch 295/300\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0428 - accuracy: 0.9967 - val_loss: 0.3514 - val_accuracy: 0.9200\n",
      "Epoch 296/300\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0411 - accuracy: 0.9967 - val_loss: 0.3401 - val_accuracy: 0.9300\n",
      "Epoch 297/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 0.9967 - val_loss: 0.3485 - val_accuracy: 0.9200\n",
      "Epoch 298/300\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 0.0381 - accuracy: 0.9967 - val_loss: 0.3382 - val_accuracy: 0.9300\n",
      "Epoch 299/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0363 - accuracy: 0.9967 - val_loss: 0.3417 - val_accuracy: 0.9300\n",
      "Epoch 300/300\n",
      "10/10 [==============================] - 0s 5ms/step - loss: 0.0350 - accuracy: 0.9967 - val_loss: 0.3407 - val_accuracy: 0.9300\n",
      "Took 16.44799 seconds\n"
     ]
    }
   ],
   "source": [
    "#Initialize lists so that their values are reset every time the Jupyter notebook is run\n",
    "X10_train_combined=[]\n",
    "y10_train_combined=[]\n",
    "X_temp=X10_train[0]\n",
    "y_temp=y10_train[0]\n",
    "\n",
    "#Essentially a running sum where you add the ith + 1 element in each iteration until reaching the end of the list\n",
    "for i in range(len(X10_train)):\n",
    "    try:\n",
    "        X_temp = np.concatenate((X_temp, X10_train[i+1]), axis=0)\n",
    "        y_temp = np.concatenate((y_temp, y10_train[i+1]), axis=0)\n",
    "    except:\n",
    "        X10_train_combined = X_temp\n",
    "        y10_train_combined = y_temp\n",
    "        break\n",
    "\n",
    "start = time()\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model_10_condensed.fit(X10_train_combined, y10_train_combined, epochs=300, validation_data=(X10_cv, y10_cv))\n",
    "\n",
    "# calculate and report duration of concatenation\n",
    "duration_10 = time() - start\n",
    "print(f'Took {duration_10:.5f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "4/4 [==============================] - 0s 1ms/step\n",
      "Training Accuracy         (regularized, 10ipc): 0.9966667\n",
      "Cross Validation Accuracy (regularized, 10ipc): 0.9300000\n",
      "Test Accuracy             (regularized, 10ipc): 0.9300000\n"
     ]
    }
   ],
   "source": [
    "#make a model for plotting routines to call\n",
    "model_predict_10 = lambda Xl: np.argmax(tf.nn.softmax(model_10_condensed.predict(Xl)).numpy(),axis=1)\n",
    "\n",
    "training_cerr_10 = eval_cat_err(y10_train_combined, model_predict_10(X10_train_combined))\n",
    "cv_cerr_10 = eval_cat_err(y10_cv, model_predict_10(X10_cv))\n",
    "test_cerr_10 = eval_cat_err(y10_test, model_predict_10(X10_test))\n",
    "print(f\"Training Accuracy         (regularized, 10ipc): {1-training_cerr_10:0.7f}\" )\n",
    "print(f\"Cross Validation Accuracy (regularized, 10ipc): {1-cv_cerr_10:0.7f}\" )\n",
    "print(f\"Test Accuracy             (regularized, 10ipc): {1-test_cerr_10:0.7f}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Training Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#Model trained on normal MNIST data\n",
    "#Tested on normal MNIST data\n",
    "\n",
    "#make a model for plotting routines to call\n",
    "model_predict = lambda Xl: np.argmax(tf.nn.softmax(model_normal.predict(Xl)).numpy(),axis=1)\n",
    "\n",
    "training_cerr_norm = eval_cat_err(train_labels, model_predict(train_images))\n",
    "test_cerr_norm = eval_cat_err(test_labels, model_predict(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#Model trained on 1ipc distilled MNIST data\n",
    "#Tested on normal MNIST data\n",
    "\n",
    "#make a model for plotting routines to call\n",
    "model_predict = lambda Xl: np.argmax(tf.nn.softmax(model_condensed.predict(Xl)).numpy(),axis=1)\n",
    "\n",
    "training_cerr_1 = eval_cat_err(y_train_combined, model_predict(X_train_combined))\n",
    "test_cerr_1 = eval_cat_err(test_labels, model_predict(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#Model trained on 10ipc distilled MNIST data\n",
    "#Tested on normal MNIST data\n",
    "\n",
    "#make a model for plotting routines to call\n",
    "model_predict_10 = lambda Xl: np.argmax(tf.nn.softmax(model_10_condensed.predict(Xl)).numpy(),axis=1)\n",
    "\n",
    "training_cerr_10 = eval_cat_err(y10_train_combined, model_predict_10(X10_train_combined))\n",
    "test_cerr_10 = eval_cat_err(test_labels, model_predict_10(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy     (regularized, non-distilled, 300 images): 0.9500000\n",
      "Test Accuracy         (regularized, non-distilled, 600 images): 0.7216667\n",
      "Time to Train                     (regularized, non-distilled): 14.38021\n",
      "Training Accuracy    (regularized, distilled: 1ipc, 30 images): 1.0000000\n",
      "Test Accuracy        (regularized, distilled: 1ipc, 10 images): 0.7283333\n",
      "Training Accuracy  (regularized, distilled: 10ipc, 300 images): 0.9966667\n",
      "Test Accuracy      (regularized, distilled: 10ipc, 600 images): 0.9250000\n",
      "Time to Train      (regularized, distilled: 10ipc, 300 images): 16.44799\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy     (regularized, non-distilled, 300 images): {1-training_cerr_norm:0.7f}\" )\n",
    "print(f\"Test Accuracy         (regularized, non-distilled, 600 images): {1-test_cerr_norm:0.7f}\" )\n",
    "print(f\"Time to Train                     (regularized, non-distilled): {duration_norm:0.5f}\" )\n",
    "print(f\"Training Accuracy    (regularized, distilled: 1ipc, 30 images): {1-training_cerr_1:0.7f}\" )\n",
    "print(f\"Test Accuracy        (regularized, distilled: 1ipc, 10 images): {1-test_cerr_1:0.7f}\" )\n",
    "print(f\"Training Accuracy  (regularized, distilled: 10ipc, 300 images): {1-training_cerr_10:0.7f}\" )\n",
    "print(f\"Test Accuracy      (regularized, distilled: 10ipc, 600 images): {1-test_cerr_10:0.7f}\" )\n",
    "print(f\"Time to Train      (regularized, distilled: 10ipc, 300 images): {duration_10:0.5f}\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
